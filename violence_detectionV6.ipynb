{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hnarges91/violence-detection/blob/main/violence_detectionV6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnGpLYeLJFFa"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# **Mount drive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3cv3TVO5h25j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e93db97f-c928-4a2b-ca27-6aa122018372"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NfAQJFp0h4_N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e304c5b-9f51-4caa-cca4-ff5ee3c9a4c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/Kaggle/datasets\n"
          ]
        }
      ],
      "source": [
        "%cd /content/gdrive/My Drive/Kaggle/datasets/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WagQw9yu2A-p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dca0edb-5b0b-4e56-a20f-70fa5ee21d5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/Kaggle/features\n"
          ]
        }
      ],
      "source": [
        "%cd /content/gdrive/My Drive/Kaggle/features/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPbtVkhWJIxV"
      },
      "source": [
        "# **Reset all variavle value**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fpIg2xghQ5Bl"
      },
      "outputs": [],
      "source": [
        "#setup\n",
        "#reset variavle value\n",
        "from IPython import get_ipython\n",
        "get_ipython().magic('reset -sf')\n",
        "#intellisence\n",
        "%config IPCcompleter.greedy = True\n",
        "import numpy as np\n",
        "np.random.seed(400)  # for reproducibility"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zt5YydzrJOhU"
      },
      "source": [
        "# **Import essential library**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "s4_nFxo9h25r"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
        "\n",
        "\n",
        "import keras , tensorflow\n",
        "from keras import models\n",
        "from keras import optimizers\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import BatchNormalization\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cd0CREsRJB17"
      },
      "source": [
        "# ***Pre_train Models***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6HJDldINO4RW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.applications import VGG16, VGG19, ResNet50\n",
        "\n",
        "\n",
        "def select_model(model_name):\n",
        "    \"\"\"\n",
        "    Choose a pre-trained convolutional neural network model for feature extraction.\n",
        "\n",
        "    Parameters:\n",
        "    - model_name: A string specifying the name of the model to use ('vgg16', 'vgg19', or 'resnet50').\n",
        "\n",
        "    Returns:\n",
        "    - model: The chosen pre-trained model.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        input_tensor = Input(shape=(224, 224, 3))\n",
        "        if model_name == 'vgg16':\n",
        "            return VGG16(weights='imagenet', include_top=False, input_tensor=input_tensor, pooling='avg')\n",
        "        elif model_name == 'vgg19':\n",
        "            return VGG19(weights='imagenet', include_top=False, input_tensor=input_tensor, pooling='avg')\n",
        "        elif model_name == 'resnet50':\n",
        "            return ResNet50(weights='imagenet', include_top=False, input_tensor=input_tensor, pooling='avg')\n",
        "        else:\n",
        "            raise ValueError(\"Invalid model name. Choose from 'vgg16', 'vgg19', or 'resnet50'.\")\n",
        "    except Exception as e:\n",
        "        print(\"Error choosing model:\", e)\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pU-mWQkQHltN"
      },
      "source": [
        "# **Dataset**\n",
        "\n",
        "# **Choose between diffrent dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QwsxRklx6pb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "118a3728-78df-47b3-b9e9-be4833e8105a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n  Returns the paths for violence and non-violence videos based on the specified dataset name.\\n\\n  Parameters:\\n  - dataset_name: Name of the dataset.\\n\\n  Returns:\\n  - v_path_frame: Path to violence frames.\\n  - nv_path_frame: Path to non-violence frames.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "  \"\"\"\n",
        "    Returns the paths for violence and non-violence videos based on the specified dataset name.\n",
        "\n",
        "    Parameters:\n",
        "    - dataset_name: Name of the dataset.\n",
        "\n",
        "    Returns:\n",
        "    - v_path_frame: Path to violence frames.\n",
        "    - nv_path_frame: Path to non-violence frames.\n",
        "  \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3qBveqO9tkBM"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def dataset_address(dataset_name):\n",
        "  if dataset_name == \"hockey\":\n",
        "    v_path_frame = \"/content/gdrive/My Drive/Kaggle/datasets/hockey_dataset/HockeyFights\"\n",
        "    nv_path_frame = \"/content/gdrive/My Drive/Kaggle/datasets/hockey_dataset/HockeyFights_no\"\n",
        "\n",
        "  elif dataset_name == \"Movies_Fight\":\n",
        "    v_path_frame = \"/content/gdrive/My Drive/Kaggle/datasets/Movies_Fight_Detection_Dataset/fights\"\n",
        "    nv_path_frame = \"/content/gdrive/My Drive/Kaggle/datasets/Movies_Fight_Detection_Dataset/noFights\"\n",
        "\n",
        "  elif dataset_name == \"violent_flow_crowd\":\n",
        "    v_path_frame = \"/content/gdrive/My Drive/Kaggle/datasets/violent_flow_crowd/Violence\"\n",
        "    nv_path_frame = \"/content/gdrive/My Drive/Kaggle/datasets/violent_flow_crowd/NonViolence\"\n",
        "\n",
        "  elif dataset_name == \"Real_Life_Violence_Dataset\":\n",
        "    v_path_frame = \"/content/gdrive/My Drive/Kaggle/datasets/Real_Life_Violence_Dataset/Violence\"\n",
        "    nv_path_frame = \"/content/gdrive/My Drive/Kaggle/datasets/Real_Life_Violence_Dataset/NonViolence\"\n",
        "\n",
        "  elif dataset_name == \"RWF\":\n",
        "    v_path_frame = \"/content/gdrive/My Drive/Kaggle/datasets/RWF/train/Fight\"\n",
        "    nv_path_frame = \"/content/gdrive/My Drive/Kaggle/datasets/RWF/train/NonFight\"\n",
        "\n",
        "  elif dataset_name == \"RWF_reconstructed\":\n",
        "    v_path_frame = \"/content/gdrive/My Drive/Kaggle/datasets/RWF_Residuals/RWF_reconstructed/train/Fight\"\n",
        "    nv_path_frame = \"/content/gdrive/My Drive/Kaggle/datasets/RWF_Residuals/RWF_reconstructed/train/NonFight\"\n",
        "\n",
        "  elif dataset_name == \"RWF_window_5\":\n",
        "    v_path_frame = \"/content/gdrive/My Drive/Kaggle/datasets/RWF_Residuals/RWF_window_5/train/Fight\"\n",
        "    nv_path_frame = \"/content/gdrive/My Drive/Kaggle/datasets/RWF_Residuals/RWF_window_5/train/NonFight\"\n",
        "\n",
        "  elif dataset_name == \"RWF_window_10\":\n",
        "    v_path_frame = \"/content/gdrive/My Drive/Kaggle/datasets/RWF_Residuals/RWF_window_10/train/Fight\"\n",
        "    nv_path_frame = \"/content/gdrive/My Drive/Kaggle/datasets/RWF_Residuals/RWF_window_10/train/NonFight\"\n",
        "\n",
        "  elif dataset_name == \"RWF_window_15\":\n",
        "    v_path_frame = \"/content/gdrive/My Drive/Kaggle/datasets/RWF_Residuals/RWF_window_15/train/Fight\"\n",
        "    nv_path_frame = \"/content/gdrive/My Drive/Kaggle/datasets/RWF_Residuals/RWF_window_15/train/NonFight\"\n",
        "\n",
        "  elif dataset_name == \"RWF_window_20\":\n",
        "    v_path_frame = \"/content/gdrive/My Drive/Kaggle/datasets/RWF_Residuals/RWF_window_20/train/Fight\"\n",
        "    nv_path_frame = \"/content/gdrive/My Drive/Kaggle/datasets/RWF_Residuals/RWF_window_20/train/NonFight\"\n",
        "\n",
        "  elif dataset_name == \"hockey_dataset_rec\":\n",
        "    v_path_frame = \"/content/gdrive/MyDrive/Kaggle/datasets/res/hockey_dataset_rec/HockeyFights\"\n",
        "    nv_path_frame = \"/content/gdrive/MyDrive/Kaggle/datasets/res/hockey_dataset_rec/HockeyFights_no\"\n",
        "\n",
        "  elif dataset_name == \"Movies_Fight_rec\":\n",
        "    v_path_frame = \"/content/gdrive/MyDrive/Kaggle/datasets/res/movie_fight_rec/fights\"\n",
        "    nv_path_frame = \"/content/gdrive/MyDrive/Kaggle/datasets/res/movie_fight_rec/noFights\"\n",
        "\n",
        "  elif dataset_name == \"violent_flow_crowd_rec\":\n",
        "    v_path_frame = \"/content/gdrive/MyDrive/Kaggle/datasets/res/violent_flow_crowd_rec/Violence\"\n",
        "    nv_path_frame = \"/content/gdrive/MyDrive/Kaggle/datasets/res/violent_flow_crowd_rec/NonViolence\"\n",
        "\n",
        "  elif dataset_name == \"real_lif_accumulated_results5\":\n",
        "    v_path_frame = \"/content/gdrive/MyDrive/Kaggle/datasets/real_lif_accumulated_results/real_life_Similarity_win5/Violence\"\n",
        "    nv_path_frame = \"/content/gdrive/MyDrive/Kaggle/datasets/real_lif_accumulated_results/real_life_Similarity_win5/NonViolence\"\n",
        "\n",
        "  elif dataset_name == \"real_lif_accumulated_results10\":\n",
        "    v_path_frame = \"/content/gdrive/MyDrive/Kaggle/datasets/real_lif_accumulated_results/real_life_Similarity_win10/Violence\"\n",
        "    nv_path_frame = \"/content/gdrive/MyDrive/Kaggle/datasets/real_lif_accumulated_results/real_life_Similarity_win10/NonViolence\"\n",
        "\n",
        "  elif dataset_name == \"real_lif_accumulated_results15\":\n",
        "    v_path_frame = \"/content/gdrive/MyDrive/Kaggle/datasets/real_lif_accumulated_results/real_life_Similarity_win15/Violence\"\n",
        "    nv_path_frame = \"/content/gdrive/MyDrive/Kaggle/datasets/real_lif_accumulated_results/real_life_Similarity_win15/NonViolence\"\n",
        "\n",
        "  elif dataset_name == \"real_lif_accumulated_results20\":\n",
        "    v_path_frame = \"/content/gdrive/MyDrive/Kaggle/datasets/real_lif_accumulated_results/real_life_Similarity_win20/Violence\"\n",
        "    nv_path_frame = \"/content/gdrive/MyDrive/Kaggle/datasets/real_lif_accumulated_results/real_life_Similarity_win20/NonViolence\"\n",
        "\n",
        "  elif dataset_name == \"real_life_reconstructed\":\n",
        "    v_path_frame = \"/content/gdrive/MyDrive/Kaggle/datasets/real_life_reconstructed/Violence\"\n",
        "    nv_path_frame = \"/content/gdrive/MyDrive/Kaggle/datasets/real_life_reconstructed/NonViolence\"\n",
        "\n",
        "    # Add more cases for other dataset names as needed\n",
        "  else:\n",
        "      # Handle the case where dataset_name is not recognized\n",
        "      print(\"Dataset name not recognized\")\n",
        "      v_path_frame = \"\"\n",
        "      nv_path_frame = \"\"\n",
        "\n",
        "  return v_path_frame,nv_path_frame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojDDdYXPe8J-"
      },
      "source": [
        "# **Load features matrix or extraxt feature**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_features(file_name):\n",
        "    \"\"\"\n",
        "    Load features from a numpy file if it exists.\n",
        "\n",
        "    Parameters:\n",
        "    - file_name: Name of the file to load features from.\n",
        "\n",
        "    Returns:\n",
        "    - features: Loaded features if the file exists, otherwise None.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if os.path.isfile(file_name):\n",
        "            print(\"File exists\")\n",
        "            loaded_matrices = np.load(file_name)\n",
        "            return [loaded_matrices[key] for key in loaded_matrices.files]\n",
        "        else:\n",
        "            print(\"File does not exist\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(\"Error loading feature file:\", e)\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "q8_O3xC7sN-_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "def load_video_features(dataset_name, model_name):\n",
        "    \"\"\"\n",
        "    Load features for violence and non-violence videos from the specified dataset and model.\n",
        "\n",
        "    Parameters:\n",
        "    - dataset_name: Name of the dataset.\n",
        "    - model_name: Name of the feature extraction model.\n",
        "    - features_dir: Directory where features are stored.\n",
        "\n",
        "    Returns:\n",
        "    - violent_features: Features extracted from violence videos.\n",
        "    - nonviolent_features: Features extracted from non-violence videos.\n",
        "    \"\"\"\n",
        "    features_dir= \"/content/gdrive/My Drive/Kaggle/features/\"\n",
        "    %cd /content/gdrive/My Drive/Kaggle/features/\n",
        "    try:\n",
        "        v_path_frame, nv_path_frame = dataset_address(dataset_name) # Assuming this function exists\n",
        "    except Exception as e:\n",
        "        print(\"Error in load_video_features:\", e)\n",
        "        return None, None\n",
        "\n",
        "    try:\n",
        "        violent_class_name = 'violent_feature'\n",
        "        violent_file_name = f\"{dataset_name}_{violent_class_name}_{model_name}.npz\"\n",
        "        violent_features = load_features(os.path.join(features_dir, violent_file_name))\n",
        "        if violent_features is None:\n",
        "            violent_features = extract_video_features(v_path_frame, model_name, violent_class_name, frame_rate=1)\n",
        "            np.savez(os.path.join(features_dir, violent_file_name), *violent_features)\n",
        "        else:\n",
        "            print(\"Violent features loaded from file.\")\n",
        "\n",
        "        nonviolent_class_name = 'nonviolent_feature'\n",
        "        nonviolent_file_name = f\"{dataset_name}_{nonviolent_class_name}_{model_name}.npz\"\n",
        "        nonviolent_features = load_features(os.path.join(features_dir, nonviolent_file_name))\n",
        "        if nonviolent_features is None:\n",
        "            nonviolent_features = extract_video_features(nv_path_frame, model_name, nonviolent_class_name, frame_rate=1)\n",
        "            np.savez(os.path.join(features_dir, nonviolent_file_name), *nonviolent_features)\n",
        "        else:\n",
        "            print(\"Non-violent features loaded from file.\")\n",
        "\n",
        "        return violent_features, nonviolent_features\n",
        "    except Exception as e:\n",
        "        print(\"Error in load_video_features:\", e)\n",
        "        return None, None\n"
      ],
      "metadata": {
        "id": "W8onB023rsa5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHhwBaDzHX6X"
      },
      "source": [
        "# ***Feature extraction***"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def extract_frame_features(frames, custom_model):\n",
        "    \"\"\"\n",
        "    Extract features from frames using a pretrained model.\n",
        "\n",
        "    Parameters:\n",
        "    - frames: Input frames as a list of numpy arrays.\n",
        "    - custom_model: Pretrained model for feature extraction.\n",
        "\n",
        "    Returns:\n",
        "    - frame_features: Features extracted from the frames as a numpy array.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        frames_resized = [cv2.resize(frame, (224, 224)) for frame in frames]\n",
        "        frame_features = custom_model.predict(np.asarray(frames_resized))\n",
        "        return frame_features\n",
        "    except Exception as e:\n",
        "        print(\"Error in extract_frame_features:\", e)\n",
        "        return None"
      ],
      "metadata": {
        "id": "Zb1hiCKOrkDg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_video_features(video_dir, model_name, class_name, frame_rate=25):\n",
        "    \"\"\"\n",
        "    Extract spatial features from videos using a pretrained model.\n",
        "\n",
        "    Parameters:\n",
        "    - video_dir: Directory containing the input videos.\n",
        "    - model_name: Name of the model.\n",
        "    - class_name: Name of the class for feature extraction.\n",
        "    - frame_rate: Rate at which frames will be extracted (e.g., every nth frame).\n",
        "\n",
        "    Returns:\n",
        "    - feature_list: List containing extracted features for all videos.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        custom_model = select_model(model_name)\n",
        "        video_counter = 0\n",
        "        videos = sorted([vfile for vfile in os.listdir(video_dir) if vfile.endswith(('.mp4', '.avi'))])\n",
        "        print(\"Number of videos:\", len(videos))\n",
        "        feature_list = []\n",
        "\n",
        "        for video in videos:\n",
        "            video_counter += 1\n",
        "            print(f\"Processing Video {video_counter}: {video}\")\n",
        "            video_path = os.path.join(video_dir, video)\n",
        "            cap = cv2.VideoCapture(video_path)\n",
        "            frames = []\n",
        "            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "            fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "            #frame_step = int(fps / frame_rate) if frame_rate != 0 else 1\n",
        "            frame_step=1\n",
        "\n",
        "            for i in range(0, frame_count, frame_step):\n",
        "                cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
        "                ret, frame = cap.read()\n",
        "                if ret:\n",
        "                    frames.append(frame)\n",
        "\n",
        "            cap.release()\n",
        "            video_features = extract_frame_features(frames, custom_model)\n",
        "            if video_features is not None:\n",
        "                feature_list.append(video_features.tolist())\n",
        "                print(\"Features shape:\", np.shape(video_features))\n",
        "                del video_features\n",
        "\n",
        "        return feature_list\n",
        "    except Exception as e:\n",
        "        print(\"Error in extract_video_features:\", e)\n",
        "        return None"
      ],
      "metadata": {
        "id": "ticmY9k0q9yS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Processing"
      ],
      "metadata": {
        "id": "xxsYxC5zBF4n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Labeling**"
      ],
      "metadata": {
        "id": "8AXLXMUX7P_d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "AZWUMiRdZVav"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def combine_and_split_features(violence_features, nonviolence_features, test_size=0.2, random_state=42):\n",
        "    \"\"\"\n",
        "    Combine features from violence and non-violence videos and split them into train and test sets.\n",
        "\n",
        "    Parameters:\n",
        "    - violence_features: Features extracted from violence videos.\n",
        "    - nonviolence_features: Features extracted from non-violence videos.\n",
        "    - test_size: Proportion of the dataset to include in the test split.\n",
        "    - random_state: Seed used by the random number generator.\n",
        "\n",
        "    Returns:\n",
        "    - X_train: Combined features for training.\n",
        "    - X_test: Combined features for testing.\n",
        "    - y_train: Combined labels for training.\n",
        "    - y_test: Combined labels for testing.\n",
        "    \"\"\"\n",
        "\n",
        "    # Randomly select samples from each class for train and test sets\n",
        "    X_train_class1, X_test_class1 = train_test_split(violence_features, test_size=test_size, random_state=random_state, shuffle=True)\n",
        "    X_train_class2, X_test_class2 = train_test_split(nonviolence_features, test_size=test_size, random_state=random_state, shuffle=True)\n",
        "\n",
        "    # Combine train and test samples\n",
        "    X_train = np.vstack((X_train_class1, X_train_class2))\n",
        "    X_test = np.vstack((X_test_class1, X_test_class2))\n",
        "\n",
        "    # Create labels\n",
        "    y_train = np.hstack((np.zeros(len(X_train_class1)), np.ones(len(X_train_class2))))\n",
        "    y_test = np.hstack((np.zeros(len(X_test_class1)), np.ones(len(X_test_class2))))\n",
        "\n",
        "    # Shuffle the train and test sets\n",
        "    train_indices = np.random.permutation(len(X_train))\n",
        "    test_indices = np.random.permutation(len(X_test))\n",
        "    X_train = X_train[train_indices]\n",
        "    X_test = X_test[test_indices]\n",
        "    y_train = y_train[train_indices]\n",
        "    y_test = y_test[test_indices]\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVXWkip5IjDh"
      },
      "source": [
        "# ***PMF***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "zscXQua0dkk8"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def pooling_feature(features, pooling_type):\n",
        "    \"\"\"\n",
        "    Perform pooling operation on the input features.\n",
        "\n",
        "    Parameters:\n",
        "    - features: List of feature arrays.\n",
        "    - pooling_type: Type of pooling operation to perform (\"mean\" or \"max\").\n",
        "\n",
        "    Returns:\n",
        "    - pooled_features: Pooled features.\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize list to store pooled features\n",
        "    pooled_features = []\n",
        "\n",
        "    # Perform pooling operation based on the specified type\n",
        "    for feature_array in features:\n",
        "        if pooling_type == \"mean\":\n",
        "            pooled_feature = np.mean(feature_array, axis=0)  # Calculate mean along each feature dimension\n",
        "        elif pooling_type == \"max\":\n",
        "            pooled_feature = np.max(feature_array, axis=0)  # Calculate max along each feature dimension\n",
        "        else:\n",
        "            raise ValueError(\"Invalid pooling_type. Use 'mean' or 'max'.\")\n",
        "\n",
        "        pooled_features.append(pooled_feature)\n",
        "\n",
        "    # Convert the list of pooled features to a numpy array\n",
        "    pooled_features = np.array(pooled_features)\n",
        "\n",
        "    return pooled_features\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpKxFk-YIvqc"
      },
      "source": [
        "# ***Classification***\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "rimvgx6fNXI6"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import regularizers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural network\n"
      ],
      "metadata": {
        "id": "A7vBmGPj7Cxu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "OqXidT_eh27_"
      },
      "outputs": [],
      "source": [
        "def neural_network_classification(X_train, y_train, input_dim):\n",
        "    \"\"\"\n",
        "    Perform neural network classification with a fully connected network having 8 layers.\n",
        "\n",
        "    Parameters:\n",
        "    - X_train: Input training features.\n",
        "    - y_train: Training labels.\n",
        "    - input_dim: Dimension of the input features.\n",
        "\n",
        "    Returns:\n",
        "    - history: Training history of the model.\n",
        "    - model: Trained neural network model.\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert labels to categorical\n",
        "    y_train = to_categorical(y_train)\n",
        "\n",
        "    # Build neural network\n",
        "    model = models.Sequential()\n",
        "    model.add(Dense(512, activation='relu', input_shape=input_dim))  # Layer 1\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(512, activation='relu'))  # Layer 2\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(512, activation='relu'))  # Layer 3\n",
        "    model.add(Dropout(0.2))  # Regularization for layer 3\n",
        "    model.add(Dense(512, activation='relu'))  # Layer 4\n",
        "    model.add(Dropout(0.2))  # Regularization for layer 4\n",
        "    # model.add(Dense(32, activation='relu'))  # Layer 5\n",
        "    # model.add(Dropout(0.2))  # Regularization for layer 5\n",
        "    model.add(Dense(2, activation='softmax'))  # Output layer\n",
        "\n",
        "    # Define early stopping callback\n",
        "    callback = keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\", min_delta=0, patience=6, verbose=1,\n",
        "        mode=\"min\", baseline=None, restore_best_weights=True\n",
        "    )\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(\n",
        "        optimizer=optimizers.Adam(learning_rate=6e-5),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # Train model\n",
        "    history = model.fit(X_train, y_train, epochs=200, verbose=0,\n",
        "                        shuffle=True, validation_split=0.2, callbacks=[callback])\n",
        "\n",
        "    return history, model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating\n",
        "# results"
      ],
      "metadata": {
        "id": "oCYHxBht7KNt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "8ucrnFGRN_Gl"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def result(x, y, history, model):\n",
        "    \"\"\"\n",
        "    Print classification report, confusion matrix, and plot accuracy and loss.\n",
        "\n",
        "    Parameters:\n",
        "    - x: Test features.\n",
        "    - y: True labels.\n",
        "    - history: History object returned by model.fit().\n",
        "    - model: Trained neural network model.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"+++ Generating result... +++\")\n",
        "\n",
        "    # Predict labels\n",
        "    pred = model.predict(x)\n",
        "    # Evaluate model\n",
        "    score = model.evaluate(x, y, verbose=0)\n",
        "    print(\"------------- Neural network classification -------------\")\n",
        "    print('Test loss:', score[0])\n",
        "    print('Test accuracy:', score[1])\n",
        "\n",
        "    real = []\n",
        "    prediction = []\n",
        "\n",
        "    # Convert predicted probabilities to labels\n",
        "    for p in pred:\n",
        "        if p[0] >= .5:\n",
        "            prediction.append(0)\n",
        "        elif p[1] >= .5:\n",
        "            prediction.append(1)\n",
        "    # Convert true labels to binary labels\n",
        "    for i in y:\n",
        "        if i[0] >= .5:\n",
        "            real.append(0)\n",
        "        elif i[1] >= .5:\n",
        "            real.append(1)\n",
        "\n",
        "    print(\"---------------------- Classification report ----------------------\")\n",
        "    print(classification_report(real, prediction))\n",
        "\n",
        "    print(\"---------------------- Confusion Matrix ----------------------\")\n",
        "    conf_mat = confusion_matrix(real, prediction)\n",
        "    print(conf_mat)\n",
        "\n",
        "    print(\"--------- Plot accuracy and loss ------\",\"\\n\")\n",
        "\n",
        "    # Plot accuracy and loss\n",
        "    plt.figure(figsize=(12,4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model Loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDAQA-eMJHbg"
      },
      "source": [
        "# ***Violence Detection***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Hrk7A5xmBU6B"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "def violence_detection(model_name, dataset_name, pooling_type):\n",
        "    \"\"\"\n",
        "    Perform violence detection using a specified model, dataset, and pooling type.\n",
        "\n",
        "    Parameters:\n",
        "    - model_name: Name of the pre-trained model to use.\n",
        "    - dataset_name: Name of the dataset.\n",
        "    - pooling_type: Type of pooling operation to perform (\"mean\" or \"max\").\n",
        "\n",
        "    Returns:\n",
        "    - accuracy: Accuracy of the violence detection model.\n",
        "    - loss: Loss of the violence detection model.\n",
        "    \"\"\"\n",
        "\n",
        "    keras.backend.clear_session()\n",
        "\n",
        "    # Extract features from pre-trained model\n",
        "    violent_feature, nonviolent_feature = load_video_features(dataset_name, model_name)\n",
        "    print(\"violent_feature\",len(violent_feature))\n",
        "    print(\"nonviolent_feature\",len(nonviolent_feature))\n",
        "    # pmf\n",
        "    print(\"pooling\")\n",
        "    v_feature = pooling_feature(violent_feature, pooling_type)\n",
        "    nonv_feature = pooling_feature(nonviolent_feature, pooling_type)\n",
        "\n",
        "    # Perform classification\n",
        "\n",
        "    X_train, X_test, y_train, y_test = combine_and_split_features(v_feature, nonv_feature)\n",
        "\n",
        "    print(\"X_train\",np.shape(X_train))\n",
        "    print(\"X_test\",np.shape(X_test))\n",
        "\n",
        "    # input_dim= (np.shape(X_train)[1],np.shape(X_train)[2])\n",
        "    input_dim=(X_train.shape[1],)\n",
        "    print(\"classification\")\n",
        "    start = time.process_time()\n",
        "    history, model = neural_network_classification(X_train, y_train, input_dim)\n",
        "    print(\"Process time:\", time.process_time() - start)\n",
        "\n",
        "    X_test = np.array(X_test)\n",
        "\n",
        "    # Predict\n",
        "    y = to_categorical(y_test)\n",
        "    pred = model.predict(X_test)\n",
        "    score = model.evaluate(X_test, y, verbose=0)\n",
        "\n",
        "    result(X_test, y, history, model)\n",
        "\n",
        "    # Clean up\n",
        "    del X_train, y_train, X_test, y_test, history, model\n",
        "    del violent_feature, nonviolent_feature , v_feature, nonv_feature\n",
        "\n",
        "    return score[1], score[0]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETeUG6Lvj1EO"
      },
      "source": [
        "# ***Initialization***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "7Xjnaf32E5CL"
      },
      "outputs": [],
      "source": [
        "#Initialization\n",
        "\n",
        "\"\"\"\n",
        "  dataset_name == \"hockey\": original hockey dataset\n",
        "  dataset_name == \"hockey_dataset_rec\": reconstructed hockey dataset\n",
        "\n",
        "  dataset_name == \"Movies_Fight\":\n",
        "  dataset_name == \"Movies_Fight_rec\":\n",
        "\n",
        "  dataset_name == \"violent_flow_crowd\":\n",
        "  dataset_name == \"violent_flow_crowd_rec\":\n",
        "\n",
        "  dataset_name == \"RWF\":\n",
        "  dataset_name == \"RWF_reconstructed\":\n",
        "\n",
        "  dataset_name == \"RWF_window_5\":\n",
        "  dataset_name == \"RWF_window_10\":\n",
        "  dataset_name == \"RWF_window_15\":\n",
        "  dataset_name == \"RWF_window_20\":\n",
        "\n",
        "\n",
        "  dataset_name == \"Real_Life_Violence_Dataset\":\n",
        "  dataset_name == \"real_life_reconstructed\":\n",
        "\n",
        "  dataset_name == \"real_lif_accumulated_results5\":\n",
        "  dataset_name == \"real_lif_accumulated_results10\":\n",
        "  dataset_name == \"real_lif_accumulated_results15\":\n",
        "  dataset_name == \"real_lif_accumulated_results20\":\n",
        "\n",

        "\"\"\"\n",
        "\n",
        "\n",
        "dataset_name = \"violent_flow_crowd\"\n",
        "model_name ='vgg19'#model can choose between  = 'vgg16','vgg19','resnet50'\n",
        "pooling_type=\"mean\" # can choose between max , mean for pooling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddIEPquCBEjx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af55d6e9-eaac-407b-b71e-0ede553e0475"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/Kaggle/features\n",
            "File does not exist\n",
            "Number of videos: 123\n",
            "Processing Video 1: Hooligans_violence__5x5_russian_hooligans_fight__Parkhom__GnfpwW6sMkc.avi\n",
            "4/4 [==============================] - 96s 18s/step\n",
            "Features shape: (101, 512)\n",
            "Processing Video 2: Hooligans_violence__ACHTUNG_skinheads_hooligans__WHITENGEL1488__H2xnId9vOo0.avi\n",
            "2/2 [==============================] - 25s 1s/step\n",
            "Features shape: (34, 512)\n",
            "Processing Video 3: Hooligans_violence__Accidents_Fights_Violence_Tragedies_Hooligans_Football_Fights_HORRIBLE_THINGS__darkhero00__PgujG07PUq0.avi\n",
            "3/3 [==============================] - 65s 18s/step\n",
            "Features shape: (83, 512)\n",
            "Processing Video 4: Hooligans_violence__Croatia_Hooligans__EXB04__JQrSRtqoU_I.avi\n",
            "5/5 [==============================] - 100s 20s/step\n",
            "Features shape: (147, 512)\n",
            "Processing Video 5: Hooligans_violence__English_Hooligans__JohnLaw__Wob3r1Leamw.avi\n",
            "4/4 [==============================] - 81s 19s/step\n",
            "Features shape: (116, 512)\n",
            "Processing Video 6: Hooligans_violence__FENERBAHCE_ULTRAS_VS_COPS_VIOLENCE_RIOT__2maxpower1453__e7Bv5fTB.avi\n",
            "5/5 [==============================] - 88s 17s/step\n",
            "Features shape: (130, 512)\n",
            "Processing Video 7: Hooligans_violence__FOOTBALL_HOOLIGANS_WEST_HAM_v_MILLWALL_AUGUST_2009_LONGER_VERSIO.avi\n",
            "4/4 [==============================] - 82s 20s/step\n",
            "Features shape: (119, 512)\n",
            "Processing Video 8: Hooligans_violence__FUCK_YOU_FOOTBALL_HOOLIGANS_RUSSIA_and_UKRAINE_part1__W00FAM__DB9PSdrfulE.avi\n",
            "5/5 [==============================] - 88s 17s/step\n",
            "Features shape: (130, 512)\n",
            "Processing Video 9: Hooligans_violence__Football_Hooligans_Carlisle_v_Preston_1993__prestonparasoccer__J.avi\n",
            "5/5 [==============================] - 91s 18s/step\n",
            "Features shape: (132, 512)\n",
            "Processing Video 10: Hooligans_violence__Football_Hooligans_Finland_v_Russia_World_Cup_Qualifier_June_2009__lancashirelads__SmxsnplMtb8.avi\n",
            "3/3 [==============================] - 46s 12s/step\n",
            "Features shape: (69, 512)\n",
            "Processing Video 11: Hooligans_violence__Football_Hooligans_Germany_v_Poland_Euro_2008__MorningGlory1997__gtaGluIXEaU.avi\n",
            "4/4 [==============================] - 70s 16s/step\n",
            "Features shape: (100, 512)\n",
            "Processing Video 12: Hooligans_violence__Football_Hooligans_Hull_Pub_Brawl_News_Report__lancashirelads__--3xfJHXlOc.avi\n",
            "4/4 [==============================] - 85s 21s/step\n",
            "Features shape: (124, 512)\n",
            "Processing Video 13: Hooligans_violence__Football_Hooligans_Preston_V_Bradford_2003__eliteborg__NLtW_TzoQm4.avi\n",
            "3/3 [==============================] - 64s 22s/step\n",
            "Features shape: (93, 512)\n",
            "Processing Video 14: Hooligans_violence__Football_Hooligans_QPR_v_Luton_St_Pancras__prestonparasoccer__DNL6VlA3hnQ.avi\n",
            "4/4 [==============================] - 67s 15s/step\n",
            "Features shape: (98, 512)\n",
            "Processing Video 15: Hooligans_violence__Football_hooligans_Reading_Swansea_1993__MrSmasherlad__9I7MpDQc82k.avi\n",
            "3/3 [==============================] - 50s 13s/step\n",
            "Features shape: (72, 512)\n",
            "Processing Video 16: Hooligans_violence__Footballs_Blood_Sport_prt2__Tramppercy__P9a6qZ3r90k.avi\n",
            "4/4 [==============================] - 80s 19s/step\n",
            "Features shape: (114, 512)\n",
            "Processing Video 17: Hooligans_violence__Fuck_police_Let_s_riot__tigerland2222__Q2k-ZHCZBAk.avi\n",
            "5/5 [==============================] - 89s 17s/step\n",
            "Features shape: (132, 512)\n",
            "Processing Video 18: Hooligans_violence__Hooligans_Untold_Story_Part_2__UltrasHooligansFilms__BXBtZwzv3EI.avi\n",
            "4/4 [==============================] - 75s 18s/step\n",
            "Features shape: (107, 512)\n",
            "Processing Video 19: Hooligans_violence__Hooligans_violence__BRANNIK_football_violence__KD666999__YTqe4xf5o6U.avi\n",
            "5/5 [==============================] - 87s 17s/step\n",
            "Features shape: (129, 512)\n",
            "Processing Video 20: Hooligans_violence__Hooligans_war_in_Russian_vk__artemorlik__6UNj6fEgz8U.avi\n",
            "4/4 [==============================] - 78s 19s/step\n",
            "Features shape: (112, 512)\n",
            "Processing Video 21: Hooligans_violence__I_D_Trailer__ImLonelyLinda__5Y26VMm4L7o.avi\n",
            "1/1 [==============================] - 17s 17s/step\n",
            "Features shape: (26, 512)\n",
            "Processing Video 22: Hooligans_violence__Koudlam_See_you_All__panrecord__nFWgiZxnz7o.avi\n",
            "5/5 [==============================] - 96s 18s/step\n",
            "Features shape: (141, 512)\n",
            "Processing Video 23: Hooligans_violence__Polish_Hooligans__tigardojaja__YLSsmo2Glyk.avi\n",
            "4/4 [==============================] - 80s 20s/step\n",
            "Features shape: (120, 512)\n",
            "Processing Video 24: Hooligans_violence__Russian_Hooligans_Zenit_St_Petersburg__LordXavior__iMjISeT72vQ.avi\n",
            "4/4 [==============================] - 78s 18s/step\n",
            "Features shape: (113, 512)\n",
            "Processing Video 25: Hooligans_violence__The_Best_Fans_in_the_World_Part_4_Hooligans__crvenobeli__3mXS25x.avi\n",
            "4/4 [==============================] - 78s 19s/step\n",
            "Features shape: (113, 512)\n",
            "Processing Video 26: Hooligans_violence__Torcida_do_Flamengo_x_PM_na_Final_da_Copa_do_Brasil__craigrj__kK.avi\n",
            "2/2 [==============================] - 39s 17s/step\n",
            "Features shape: (57, 512)\n",
            "Processing Video 27: audience_violence__Riot_police_attack_peaceful_protesters_at_G20_Climate_Camp__bristlekrs__t244-zEENSs.avi\n",
            "3/3 [==============================] - 55s 17s/step\n",
            "Features shape: (82, 512)\n",
            "Processing Video 28: balcony_football_violence__Brannik_Football_Violence__Nattevandring__ysW-tGv-YjI.avi\n",
            "3/3 [==============================] - 66s 22s/step\n",
            "Features shape: (95, 512)\n",
            "Processing Video 29: balcony_football_violence__British_Football_Hooligans_Mix_1__MorningGlory1997__pn6CNLi3UhA.avi\n",
            "4/4 [==============================] - 67s 15s/step\n",
            "Features shape: (99, 512)\n",
            "Processing Video 30: balcony_football_violence__British_Football_Hooligans_Mix_3__MorningGlory1997__kW23lUV6oFk.avi\n",
            "4/4 [==============================] - 75s 18s/step\n",
            "Features shape: (112, 512)\n",
            "Processing Video 31: balcony_football_violence__Football_Hooligans_Bury_v_Stockport_1998__MorningGlory1997__g6p_k37oWws.avi\n",
            "5/5 [==============================] - 106s 21s/step\n",
            "Features shape: (156, 512)\n",
            "Processing Video 32: balcony_football_violence__Football_Hooligans_Leeds_v_Wolves_2005__MorningGlory1997__f66MTrNLPL0.avi\n",
            "5/5 [==============================] - 87s 16s/step\n",
            "Features shape: (129, 512)\n",
            "Processing Video 33: balcony_football_violence__Football_Hooligans_Oxford_Utd_v_Aston_Villa_2002__MorningGlory1997__bWY8AQIFYXM.avi\n",
            "4/4 [==============================] - 80s 19s/step\n",
            "Features shape: (119, 512)\n",
            "Processing Video 34: balcony_football_violence__Football_Hooligans_Watford_v_Luton_2002_Version_1__MorningGlory1997__vLOTaR9eMlg.avi\n",
            "4/4 [==============================] - 69s 16s/step\n",
            "Features shape: (103, 512)\n",
            "Processing Video 35: balcony_football_violence__Football_Hooligans_Watford_v_Luton_2002_Version_2__MorningGlory1997__1XbY1Sr2Obw.avi\n",
            "4/4 [==============================] - 85s 20s/step\n",
            "Features shape: (116, 512)\n",
            "Processing Video 36: balcony_football_violence__Football_Violence_Gais_AIK_2005__spliffpolitics__e4xiTNkfN0U.avi\n",
            "4/4 [==============================] - 68s 16s/step\n",
            "Features shape: (100, 512)\n",
            "Processing Video 37: crowd_violence__Crowd_Violence_Control_techniques__mackevster__wkva5YERsRg.avi\n",
            "4/4 [==============================] - 67s 16s/step\n",
            "Features shape: (97, 512)\n",
            "Processing Video 38: crowd_violence__FooTBaLL_Violence__dyster8__iN4kiCHg2S4.avi\n",
            "3/3 [==============================] - 48s 14s/step\n",
            "Features shape: (73, 512)\n",
            "Processing Video 39: crowd_violence__Man_Utd_vs_Roma_Crowd_Trouble__uncychris__ZGI5vlDMpJA.avi\n",
            "3/3 [==============================] - 44s 11s/step\n",
            "Features shape: (65, 512)\n",
            "Processing Video 40: crowd_violence__Roma_V_Man_Utd_Police_beating_crowd__Beck84Utd__jwtg8AkcAfc.avi\n",
            "4/4 [==============================] - 88s 21s/step\n",
            "Features shape: (128, 512)\n",
            "Processing Video 41: crowd_violence__Rostock_Anti_G8_Demo_Police_Violence__erikaransom__f185olt6W4I.avi\n",
            "3/3 [==============================] - 54s 16s/step\n",
            "Features shape: (80, 512)\n",
            "Processing Video 42: crowd_violence__Violence_At_Upton_Park_25_08_09__JunaidNixamani__MgXe0isUnSg.avi\n",
            "4/4 [==============================] - 74s 18s/step\n",
            "Features shape: (108, 512)\n",
            "Processing Video 43: fans_violence__Accidents_Fights_Violence_Tragedies_Hooligans_Football_Fights_HORRIBLE_THINGS__darkhero00__PgujG07PUq0.avi\n",
            "5/5 [==============================] - 92s 17s/step\n",
            "Features shape: (130, 512)\n",
            "Processing Video 44: fans_violence__BRANNIK_Football_Violence_CSKA__Arpecua__gew9Ks_9VRU.avi\n",
            "1/4 [======>.......................] - ETA: 1:11"
          ]
        }
      ],
      "source": [
        "losss=[]\n",
        "accs=[]\n",
        "tag=0 # for print neural network result for 1 time and svm classification\n",
        "for i in range (0,20):\n",
        "  acc,loss= violence_detection(model_name, dataset_name, pooling_type)\n",
        "  accs.append(acc)\n",
        "  losss.append(loss)\n",
        "  print(\"-------------------\")\n",
        "  print(\"+++ mean ... +++\")\n",
        "  acc_mean= np.mean(accs)\n",
        "  loss_mean=np.mean(losss)\n",
        "  print(acc_mean)\n",
        "  print(loss_mean)\n",
        "\n",
        "print(\"-------------------\")\n",
        "print(\"+++ median ... +++\")\n",
        "median_acc = np.median(accs)\n",
        "median_loss = np.median(losss)\n",
        "print(median_acc)\n",
        "print(median_loss)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
